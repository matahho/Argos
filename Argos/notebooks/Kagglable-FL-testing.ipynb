{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977513d9512cf33f",
   "metadata": {},
   "source": [
    "## NOTE : For running this notebook you should download the dataset from :\n",
    "###    https://www.kaggle.com/datasets/nomihsa965/traffic-signs-dataset-mapillary-and-dfg\n",
    "##    and then put it in the main directory (Argos/) by \"data\" naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98ea2ab790c9356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:01.545193Z",
     "start_time": "2025-07-31T13:37:01.056474Z"
    }
   },
   "outputs": [],
   "source": [
    "import model\n",
    "!pip3 install -q \"flwr[simulation]\" \"flwr-datasets[vision]\" torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63417e47455adfe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:02.128473Z",
     "start_time": "2025-07-31T13:37:01.569721Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import mps , cuda\n",
    "import torch\n",
    "\n",
    "\n",
    "def device_allocation():\n",
    "    if mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205467574375d462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:02.207069Z",
     "start_time": "2025-07-31T13:37:02.193844Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Server Settings\n",
    "NUMBER_OF_CLIENTS = 2\n",
    "\n",
    "# Clients' Settings\n",
    "CLIENT_BATCH_SIZE = 32\n",
    "CLIENT_LEARNING_RATE = 0.001\n",
    "DEVICE = device_allocation()\n",
    "\n",
    "\n",
    "# Dataset\n",
    "DATASET_PATH = \"../data/\"\n",
    "CLASSES_JSON_FILE = os.path.join(DATASET_PATH, \"classes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5881344ad38f7b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:02.821266Z",
     "start_time": "2025-07-31T13:37:02.232009Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import ops\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_model(num_classes, checkpoint_path=None, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Returns a Faster R-CNN model with the specified number of output classes.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of object classes (including background).\n",
    "        checkpoint_path (str, optional): Path to load pretrained weights (optional).\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): Faster R-CNN model ready for training.\n",
    "    \"\"\"\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Replace the pre-trained head with a new one for our custom classes\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "    if checkpoint_path:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "        print(f\"Loaded model weights from: {checkpoint_path}\")\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Trains Faster R-CNN model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The Faster R-CNN model.\n",
    "        dataloader (DataLoader): A PyTorch DataLoader returning (images, targets).\n",
    "        optimizer (torch.optim.Optimizer): Optimizer (e.g., SGD).\n",
    "        device (torch.device): CUDA or CPU.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss (float): Average loss over the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for images, targets in pbar:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += losses.item()\n",
    "        pbar.set_postfix(loss=losses.item())\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, device=DEVICE, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate a Faster R-CNN model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained Faster R-CNN model.\n",
    "        dataloader (DataLoader): Validation/test dataloader.\n",
    "        device (torch.device): \"cuda\" or \"cpu\".\n",
    "        iou_threshold (float): IoU threshold for counting correct detections.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss (float): Average loss on dataset.\n",
    "        accuracy (float): Detection accuracy based on IoU.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(dataloader)\n",
    "    correct_detections = 0\n",
    "    total_targets = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "        for images, targets in pbar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            total_loss += losses.item()\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            for output, target in zip(outputs, targets):\n",
    "                pred_boxes = output['boxes']\n",
    "                pred_labels = output['labels']\n",
    "                gt_boxes = target['boxes']\n",
    "                gt_labels = target['labels']\n",
    "\n",
    "                total_targets += len(gt_boxes)\n",
    "\n",
    "                if len(pred_boxes) == 0 or len(gt_boxes) == 0:\n",
    "                    continue\n",
    "\n",
    "                ious = ops.box_iou(pred_boxes, gt_boxes)\n",
    "\n",
    "                max_iou_per_gt, matched_preds = ious.max(dim=0)\n",
    "                correct = (max_iou_per_gt > iou_threshold).sum().item()\n",
    "                correct_detections += correct\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracy = correct_detections / total_targets if total_targets > 0 else 0.0\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e573ffc7d70e9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:02.847055Z",
     "start_time": "2025-07-31T13:37:02.840746Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from functools import cache\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "def extract_label_mapping(classes_file):\n",
    "    label_map = {}\n",
    "    try:\n",
    "        with open(classes_file, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "            for class_name, details in json_data.items():\n",
    "                if \"classIndex\" in details:\n",
    "                    label_map[details[\"classIndex\"]] = class_name\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Classes file not found at {classes_file}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from {classes_file}. Check file format.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    return label_map\n",
    "\n",
    "\n",
    "class MTSDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root_dir,\n",
    "            images_dir=\"images\",\n",
    "            annotations_dir=\"txts (YOLO)\",\n",
    "            transform=transforms.Compose([transforms.ToTensor()])\n",
    "    ):\n",
    "\n",
    "        self.root_directory = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images_names = sorted(\n",
    "            os.listdir(\n",
    "                os.path.join(self.root_directory, images_dir)\n",
    "            )\n",
    "        )\n",
    "        self.full_images_directory = os.path.join(self.root_directory, images_dir)\n",
    "        self.full_annotations_directory = os.path.join(self.root_directory, annotations_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.images_names[idx]\n",
    "\n",
    "        img_path = os.path.join(self.full_images_directory, file_name)\n",
    "        ann_path = os.path.join(self.full_annotations_directory, file_name[:-4] + '.txt')\n",
    "\n",
    "        #print(img_path)\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        w, h = img.size\n",
    "        img_tensor = self.transform(img)\n",
    "\n",
    "        objects = []\n",
    "        try:\n",
    "            with open(ann_path, 'r') as f:\n",
    "                for row in f.readlines():\n",
    "                    objects.append(row.split())\n",
    "        except FileNotFoundError:\n",
    "            logging.warning(f\"File {ann_path} not found.\")\n",
    "            pass\n",
    "        # print(objects)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in objects:\n",
    "            # YOLO format: [class_id, x_center, y_center, width, height] (all normalized)\n",
    "            class_id, cx, cy, bw, bh = map(float, obj)\n",
    "            xmin = (cx - bw / 2) * w\n",
    "            ymin = (cy - bh / 2) * h\n",
    "            xmax = (cx + bw / 2) * w\n",
    "            ymax = (cy + bh / 2) * h\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(int(class_id))\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx])\n",
    "        }\n",
    "\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "\n",
    "@cache\n",
    "def partition_dataset(dataset, num_clients):\n",
    "    label_to_indices = defaultdict(list)\n",
    "\n",
    "    logging.info(f\"Starting Partitioning dataset into {num_clients} clients.\")\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        _, target = dataset[idx]\n",
    "        labels = target['labels'].unique().tolist()\n",
    "        for label in labels:\n",
    "            label_to_indices[label].append(idx)\n",
    "\n",
    "    label_ids = list(label_to_indices.keys())\n",
    "    random.shuffle(label_ids)\n",
    "\n",
    "    client_data = defaultdict(list)\n",
    "    for client_id in range(num_clients):\n",
    "        assigned_labels = label_ids[client_id::num_clients]\n",
    "        for lbl in assigned_labels:\n",
    "            client_data[client_id].extend(label_to_indices[lbl])\n",
    "\n",
    "    logging.info(f\" Partitioning dataset into {num_clients} clients finished.\")\n",
    "\n",
    "    return client_data\n",
    "\n",
    "\n",
    "def get_dataset_for_client(\n",
    "        partition_id,\n",
    "        full_dataset,\n",
    "        partitioned_dataset_indices:dict,\n",
    "        train_percentage=0.8, val_percentage=0.1, test_percentage=0.1\n",
    ") -> [Subset , Subset , Subset]:\n",
    "\n",
    "    assert abs(train_percentage + val_percentage + test_percentage - 1.0) < 1e-4, \\\n",
    "        \"Splits must sum to 1.0\"\n",
    "\n",
    "    assert partition_id in list(partitioned_dataset_indices.keys()) , \"Client id must be in partitioned dataset keys\"\n",
    "\n",
    "    client_samples = partitioned_dataset_indices[partition_id]\n",
    "    random.shuffle(client_samples)\n",
    "\n",
    "    total = len(client_samples)\n",
    "    train_end = int(total * train_percentage)\n",
    "    val_end = train_end + int(total * val_percentage)\n",
    "\n",
    "    train_ids = client_samples[:train_end]\n",
    "    val_ids = client_samples[train_end:val_end]\n",
    "    test_ids = client_samples[val_end:]\n",
    "\n",
    "    train_set = Subset(full_dataset, train_ids)\n",
    "    val_set = Subset(full_dataset, val_ids)\n",
    "    test_set = Subset(full_dataset, test_ids)\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2192f9862ebf81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.194960Z",
     "start_time": "2025-07-31T13:37:02.871857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-31 17:24:38,083\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import torch.optim as optim\n",
    "\n",
    "class Client(fl.client.NumPyClient):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            train_dataset,\n",
    "            eval_dataset,\n",
    "            device=DEVICE,\n",
    "            learning_rate=CLIENT_LEARNING_RATE,\n",
    "            batch_size=CLIENT_BATCH_SIZE,\n",
    "            optimizer=None,\n",
    "\n",
    "    ):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=lambda x: tuple(zip(*x))\n",
    "        )\n",
    "        self.eval_loader = torch.utils.data.DataLoader(\n",
    "            dataset=eval_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=lambda x: tuple(zip(*x))\n",
    "        )\n",
    "\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate) if not optimizer else optimizer\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [\n",
    "            val.cpu().numpy() for _, val in self.model.state_dict().items()\n",
    "        ]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        model.train()\n",
    "        train(\n",
    "            model=self.model,\n",
    "            dataloader=self.train_loader,\n",
    "            optimizer=self.optimizer,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        return self.get_parameters(config={}), len(self.train_loader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        avg_loss , accuracy = evaluate(\n",
    "            model=self.model,\n",
    "            dataloader=self.eval_loader,\n",
    "        )\n",
    "        return avg_loss, len(self.eval_loader), {\"accuracy\": accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b905d5c372b1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.201910Z",
     "start_time": "2025-07-31T13:37:03.200645Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007b58605e20f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.206779Z",
     "start_time": "2025-07-31T13:37:03.205563Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacb063be357c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.221219Z",
     "start_time": "2025-07-31T13:37:03.219922Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98da881bc3ca50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.242117Z",
     "start_time": "2025-07-31T13:37:03.240857Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a548f942aa80914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.250257Z",
     "start_time": "2025-07-31T13:37:03.249029Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2645affc2101b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.266660Z",
     "start_time": "2025-07-31T13:37:03.265498Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8f200d18c4f1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.280716Z",
     "start_time": "2025-07-31T13:37:03.279380Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461f6217656e378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.290782Z",
     "start_time": "2025-07-31T13:37:03.289521Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca240f616a63320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.305795Z",
     "start_time": "2025-07-31T13:37:03.304551Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bff3aeb313a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.319928Z",
     "start_time": "2025-07-31T13:37:03.318719Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.330663Z",
     "start_time": "2025-07-31T13:37:03.329461Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a76bc5eb1e1f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:03.354350Z",
     "start_time": "2025-07-31T13:37:03.353033Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e766be852e90676b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.573760Z",
     "start_time": "2025-07-31T13:37:03.368237Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "label_mapping = extract_label_mapping(CLASSES_JSON_FILE)\n",
    "number_of_classes = len(label_mapping)\n",
    "dataset = MTSDDataset(root_dir=DATASET_PATH)\n",
    "dataset = Subset(dataset, list(range(20)))\n",
    "partitioned_dataset_indices = partition_dataset(dataset=dataset, num_clients=NUMBER_OF_CLIENTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "207909a41dfd7a64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.581974Z",
     "start_time": "2025-07-31T13:37:04.579124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [6,\n",
       "              13,\n",
       "              0,\n",
       "              8,\n",
       "              15,\n",
       "              16,\n",
       "              19,\n",
       "              5,\n",
       "              4,\n",
       "              3,\n",
       "              8,\n",
       "              11,\n",
       "              13,\n",
       "              14,\n",
       "              13,\n",
       "              14,\n",
       "              10,\n",
       "              11,\n",
       "              15,\n",
       "              14],\n",
       "             1: [0, 12, 14, 7, 6, 9, 13, 2, 7, 10, 18, 18, 1, 17]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned_dataset_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a37a904e1c7a98",
   "metadata": {},
   "source": [
    "## Client App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5df96ab358c599b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.594351Z",
     "start_time": "2025-07-31T13:37:04.592224Z"
    }
   },
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "from flwr.client import ClientApp\n",
    "\n",
    "\n",
    "def new_client(context : Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    neural_network = get_model(\n",
    "        num_classes=number_of_classes\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    train_dataset , val_dataset ,test_dataset = get_dataset_for_client(\n",
    "        partition_id=partition_id,\n",
    "        full_dataset=dataset,\n",
    "        partitioned_dataset_indices=partitioned_dataset_indices,\n",
    "    )\n",
    "\n",
    "\n",
    "    return Client(\n",
    "        model=neural_network,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        learning_rate=CLIENT_LEARNING_RATE,\n",
    "        batch_size=CLIENT_BATCH_SIZE,\n",
    "    ).to_client()\n",
    "\n",
    "\n",
    "\n",
    "client = ClientApp(client_fn=new_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb47eba58be1e7",
   "metadata": {},
   "source": [
    "## Server App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9809e3ced8b51eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.599941Z",
     "start_time": "2025-07-31T13:37:04.598525Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "strategy = FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4719047ee6aad726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.608189Z",
     "start_time": "2025-07-31T13:37:04.606414Z"
    }
   },
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "from flwr.server import ServerAppComponents, ServerConfig, ServerApp\n",
    "\n",
    "\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    \"\"\"Construct components that set the ServerApp behaviour.\n",
    "\n",
    "    You can use the settings in `context.run_config` to parameterize the\n",
    "    construction of all elements (e.g the strategy or the number of rounds)\n",
    "    wrapped in the returned ServerAppComponents object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure the server for 5 rounds of training\n",
    "    config = ServerConfig(num_rounds=2,round_timeout=30.0)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9c54009c6f98de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.613261Z",
     "start_time": "2025-07-31T13:37:04.611832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 2x CPU and 0x GPUs\n",
    "\n",
    "backend_config = {\n",
    "    \"client_resources\": {\n",
    "        \"num_cpus\": 6, \"num_gpus\": 0.0\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42299d51a966bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:04.620635Z",
     "start_time": "2025-07-31T13:37:04.619524Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf866d3983de39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:37:19.068365Z",
     "start_time": "2025-07-31T13:37:11.476938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:flwr:Asyncio event loop already running.\n",
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, round_timeout=30.0s\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Requesting initial parameters from one random client\n",
      "\u001B[91mERROR \u001B[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001B[91mERROR \u001B[0m:     cannot access local variable 'future' where it is not associated with a value\n",
      "\u001B[91mERROR \u001B[0m:     Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 912, in ray._raylet.prepare_args_internal\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/_private/serialization.py\", line 519, in serialize\n",
      "    return self._serialize_to_msgpack(value)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/_private/serialization.py\", line 497, in _serialize_to_msgpack\n",
      "    pickle5_serialized_object = self._serialize_to_pickle5(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/_private/serialization.py\", line 444, in _serialize_to_pickle5\n",
      "    raise e\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/_private/serialization.py\", line 439, in _serialize_to_pickle5\n",
      "    inband = pickle.dumps(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/cloudpickle/cloudpickle.py\", line 1479, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/cloudpickle/cloudpickle.py\", line 1245, in dump\n",
      "    return super().dump(obj)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "TypeError: cannot pickle '_Ops' object\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 166, in process_message\n",
      "    future = self.pool.submit(\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 463, in submit\n",
      "    future = actor_fn(actor, app_fn, mssg, cid, context)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 167, in <lambda>\n",
      "    lambda a, a_fn, mssg, cid, state: a.run.remote(a_fn, mssg, cid, state),\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/actor.py\", line 202, in remote\n",
      "    return self._remote(args, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/util/tracing/tracing_helper.py\", line 426, in _start_span\n",
      "    return method(self, args, kwargs, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/actor.py\", line 330, in _remote\n",
      "    return invocation(args, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/actor.py\", line 311, in invocation\n",
      "    return actor._actor_method_call(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ray/actor.py\", line 1463, in _actor_method_call\n",
      "    object_refs = worker.core_worker.submit_actor_task(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"python/ray/_raylet.pyx\", line 4250, in ray._raylet.CoreWorker.submit_actor_task\n",
      "  File \"python/ray/_raylet.pyx\", line 4255, in ray._raylet.CoreWorker.submit_actor_task\n",
      "  File \"python/ray/_raylet.pyx\", line 871, in ray._raylet.prepare_args_and_increment_put_refs\n",
      "  File \"python/ray/_raylet.pyx\", line 862, in ray._raylet.prepare_args_and_increment_put_refs\n",
      "  File \"python/ray/_raylet.pyx\", line 921, in ray._raylet.prepare_args_internal\n",
      "TypeError: Could not serialize the argument <function start_vce.<locals>._load at 0x16a50b060> for a task or actor flwr.simulation.ray_transport.ray_actor.ClientAppActor.run:\n",
      "==============================================================================\n",
      "Checking Serializability of <function start_vce.<locals>._load at 0x16a50b060>\n",
      "==============================================================================\n",
      "\u001B[31m!!! FAIL\u001B[39m serialization: cannot pickle '_Ops' object\n",
      "Detected 1 global variables. Checking serializability...\n",
      "    Serializing 'get_load_client_app_fn' <function get_load_client_app_fn at 0x1682494e0>...\n",
      "Detected 5 nonlocal variables. Checking serializability...\n",
      "    Serializing 'app_dir' /Users/mahdi/Desktop/CPS/CAVs-FL/Argos/notebooks...\n",
      "    Serializing 'client_app' <flwr.client.client_app.ClientApp object at 0x16a50f750>...\n",
      "    \u001B[31m!!! FAIL\u001B[39m serialization: cannot pickle '_Ops' object\n",
      "        Serializing '_call' <function ClientApp.__init__.<locals>.ffn at 0x16a50a8e0>...\n",
      "        \u001B[31m!!! FAIL\u001B[39m serialization: cannot pickle '_Ops' object\n",
      "        Detected 1 global variables. Checking serializability...\n",
      "            Serializing 'handle_legacy_message_from_msgtype' <function handle_legacy_message_from_msgtype at 0x168000400>...\n",
      "        Detected 1 nonlocal variables. Checking serializability...\n",
      "            Serializing 'client_fn' <function new_client at 0x16a50a660>...\n",
      "            \u001B[31m!!! FAIL\u001B[39m serialization: cannot pickle '_Ops' object\n",
      "        Serializing '_call' <function ClientApp.__init__.<locals>.ffn at 0x16a50a8e0>...\n",
      "        \u001B[31m!!! FAIL\u001B[39m serialization: cannot pickle '_Ops' object\n",
      "        Detected 1 global variables. Checking serializability...\n",
      "            Serializing 'handle_legacy_message_from_msgtype' <function handle_legacy_message_from_msgtype at 0x168000400>...\n",
      "        Detected 1 nonlocal variables. Checking serializability...\n",
      "            Serializing 'client_fn' <function new_client at 0x16a50a660>...\n",
      "            \u001B[31m!!! FAIL\u001B[39m serialization: cannot pickle '_Ops' object\n",
      "==============================================================================\n",
      "Variable: \n",
      "\n",
      "\t\u001B[1mFailTuple(client_fn [obj=<function new_client at 0x16a50a660>, parent=<function ClientApp.__init__.<locals>.ffn at 0x16a50a8e0>])\n",
      "FailTuple(client_fn [obj=<function new_client at 0x16a50a660>, parent=<function ClientApp.__init__.<locals>.ffn at 0x16a50a8e0>])\u001B[0m\n",
      "\n",
      "was found to be non-serializable. There may be multiple other undetected variables that were non-serializable. \n",
      "Consider either removing the instantiation/imports of these variables or moving the instantiation into the scope of the function/class. \n",
      "==============================================================================\n",
      "Check https://docs.ray.io/en/master/ray-core/objects/serialization.html#troubleshooting for more information.\n",
      "If you have any suggestions on how to improve this error message, please reach out to the Ray developers on github.com/ray-project/ray/issues/\n",
      "==============================================================================\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 112, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 186, in process_message\n",
      "    self.pool.add_actor_back_to_pool(future)\n",
      "                                     ^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'future' where it is not associated with a value\n",
      "\n",
      "\u001B[91mERROR \u001B[0m:     ServerApp thread raised an exception: Message contains an Error (reason: <class 'UnboundLocalError'>:<'cannot access local variable 'future' where it is not associated with a value'>). It originated during client-side execution of a message.\n",
      "\u001B[91mERROR \u001B[0m:     Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/simulation/run_simulation.py\", line 285, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/compat/app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server.py\", line 93, in fit\n",
      "    self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server.py\", line 284, in _get_initial_parameters\n",
      "    get_parameters_res = random_client.get_parameters(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/compat/grid_client_proxy.py\", line 63, in get_parameters\n",
      "    in_recorddict = self._send_receive_recorddict(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/compat/grid_client_proxy.py\", line 131, in _send_receive_recorddict\n",
      "    raise ValueError(\n",
      "ValueError: Message contains an Error (reason: <class 'UnboundLocalError'>:<'cannot access local variable 'future' where it is not associated with a value'>). It originated during client-side execution of a message.\n",
      "\n",
      "Exception in thread Thread-5 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/simulation/run_simulation.py\", line 285, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/compat/app.py\", line 90, in start_grid\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server.py\", line 93, in fit\n",
      "    self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/server.py\", line 284, in _get_initial_parameters\n",
      "    get_parameters_res = random_client.get_parameters(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/compat/grid_client_proxy.py\", line 63, in get_parameters\n",
      "    in_recorddict = self._send_receive_recorddict(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/server/compat/grid_client_proxy.py\", line 131, in _send_receive_recorddict\n",
      "    raise ValueError(\n",
      "ValueError: Message contains an Error (reason: <class 'UnboundLocalError'>:<'cannot access local variable 'future' where it is not associated with a value'>). It originated during client-side execution of a message.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mflwr\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msimulation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m run_simulation\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mrun_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mserver_app\u001B[49m\u001B[43m=\u001B[49m\u001B[43mserver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclient_app\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_supernodes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mNUMBER_OF_CLIENTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbackend_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbackend_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:228\u001B[39m, in \u001B[36mrun_simulation\u001B[39m\u001B[34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001B[39m\n\u001B[32m    218\u001B[39m     warn_deprecated_feature_with_example(\n\u001B[32m    219\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPassing `enable_tf_gpu_growth=True` is deprecated.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    220\u001B[39m         example_message=\u001B[33m\"\u001B[39m\u001B[33mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    223\u001B[39m         \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[33mflwr.simulation.run_simulationt(...)\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    224\u001B[39m     )\n\u001B[32m    226\u001B[39m _check_ray_support(backend_name)\n\u001B[32m--> \u001B[39m\u001B[32m228\u001B[39m _ = \u001B[43m_run_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    229\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_supernodes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_supernodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclient_app\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclient_app\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    231\u001B[39m \u001B[43m    \u001B[49m\u001B[43mserver_app\u001B[49m\u001B[43m=\u001B[49m\u001B[43mserver_app\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    232\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbackend_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbackend_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    233\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbackend_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbackend_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    234\u001B[39m \u001B[43m    \u001B[49m\u001B[43menable_tf_gpu_growth\u001B[49m\u001B[43m=\u001B[49m\u001B[43menable_tf_gpu_growth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    235\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose_logging\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose_logging\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    236\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexit_event\u001B[49m\u001B[43m=\u001B[49m\u001B[43mEventType\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:527\u001B[39m, in \u001B[36m_run_simulation\u001B[39m\u001B[34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001B[39m\n\u001B[32m    523\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m asyncio_loop_running:\n\u001B[32m    524\u001B[39m         \u001B[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001B[39;00m\n\u001B[32m    525\u001B[39m         logger = set_logger_propagation(logger, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m527\u001B[39m     updated_context = \u001B[43m_main_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    528\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m updated_context\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:425\u001B[39m, in \u001B[36m_main_loop\u001B[39m\u001B[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001B[39m\n\u001B[32m    423\u001B[39m         serverapp_th.join()\n\u001B[32m    424\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m server_app_thread_has_exception.is_set():\n\u001B[32m--> \u001B[39m\u001B[32m425\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mException in ServerApp thread\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    427\u001B[39m log(DEBUG, \u001B[33m\"\u001B[39m\u001B[33mStopping Simulation Engine now.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    428\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m updated_context\n",
      "\u001B[31mRuntimeError\u001B[39m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUMBER_OF_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e83bed2521700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:31:18.074581Z",
     "start_time": "2025-07-31T13:06:10.527390Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f654d8efc7069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:58:40.735619Z",
     "start_time": "2025-07-26T13:58:40.734126Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3848e167dd6b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:58:40.792034Z",
     "start_time": "2025-07-26T13:58:40.790481Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
